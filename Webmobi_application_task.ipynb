{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**WEBMOBI INTERNSHIP APPLICATION TASK**"
      ],
      "metadata": {
        "id": "OgntQMfPJSPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwGhciuQ_yqt",
        "outputId": "9edc6794-4a9e-4f8e-e274-2e285fb1592d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-fefdc495c9c1>:16: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  date_time_tag = soup.find('div', text='Date and time')\n",
            "<ipython-input-8-fefdc495c9c1>:24: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  location_tag = soup.find('div', text='Location')\n",
            "<ipython-input-8-fefdc495c9c1>:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  description_tag = soup.find('div', text='About this event')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping completed and data saved to CSV file.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def fetch_event_data(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    event_data = {}\n",
        "\n",
        "    # Extracting Event Name\n",
        "    event_name_tag = soup.find('h1')\n",
        "    event_data['Event Name'] = event_name_tag.text.strip() if event_name_tag else 'Not available'\n",
        "\n",
        "    # Extracting Event Date(s)\n",
        "    date_time_tag = soup.find('div', text='Date and time')\n",
        "    if date_time_tag:\n",
        "        date_time_text = date_time_tag.find_next('div').text.strip()\n",
        "    else:\n",
        "        date_time_text = 'Not available'\n",
        "    event_data['Event Date(s)'] = date_time_text\n",
        "\n",
        "    # Extracting Location\n",
        "    location_tag = soup.find('div', text='Location')\n",
        "    if location_tag:\n",
        "        location_text = location_tag.find_next('div').text.strip()\n",
        "    else:\n",
        "        location_text = 'Not available'\n",
        "    event_data['Location'] = location_text\n",
        "\n",
        "    # Extracting Website URL\n",
        "    event_data['Website URL'] = url\n",
        "\n",
        "    # Extracting Description\n",
        "    description_tag = soup.find('div', text='About this event')\n",
        "    if description_tag:\n",
        "        description_text = description_tag.find_next('div').text.strip()\n",
        "    else:\n",
        "        description_text = 'Not available'\n",
        "    event_data['Description'] = description_text\n",
        "\n",
        "    # Extracting Key Speakers (assuming speakers might be in the description)\n",
        "    key_speakers = []\n",
        "    if 'speakers' in description_text.lower():\n",
        "        key_speakers = [line.strip() for line in description_text.split('\\n') if 'speaker' in line.lower()]\n",
        "    event_data['Key Speakers'] = key_speakers if key_speakers else 'Not available'\n",
        "\n",
        "    # Extracting Agenda/Schedule (assuming the agenda might be in the description)\n",
        "    agenda_tags = description_tag.find_all('p') if description_tag else []\n",
        "    event_data['Agenda/Schedule'] = [item.text.strip() for item in agenda_tags] if agenda_tags else 'Not available'\n",
        "\n",
        "    # Extracting Registration Details (looking for pricing info)\n",
        "    registration_details_tag = soup.find('div', class_='js-ticket-list')\n",
        "    event_data['Registration Details'] = registration_details_tag.text.strip() if registration_details_tag else 'Not available'\n",
        "\n",
        "    # Extracting Pricing\n",
        "    pricing_tag = registration_details_tag\n",
        "    event_data['Pricing'] = pricing_tag.text.strip() if pricing_tag else 'Not available'\n",
        "\n",
        "    # Extracting Categories (assuming categories might be in tags or description)\n",
        "    categories_tags = soup.find_all('div', class_='eds-event-card-content__sub-content')\n",
        "    event_data['Categories'] = [category.text.strip() for category in categories_tags] if categories_tags else 'Not available'\n",
        "\n",
        "    # Extracting Audience Type (assuming audience type might be in description)\n",
        "    audience_tags = [line.strip() for line in description_text.split('\\n') if 'audience' in line.lower()]\n",
        "    event_data['Audience type'] = audience_tags if audience_tags else 'Not available'\n",
        "\n",
        "    return event_data\n",
        "\n",
        "def save_to_csv(data, filename='events_data.csv'):\n",
        "    keys = data[0].keys()\n",
        "    with open(filename, 'w', newline='') as csv_file:\n",
        "        dict_writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
        "        dict_writer.writeheader()\n",
        "        dict_writer.writerows(data)\n",
        "\n",
        "# List of event URLs\n",
        "event_urls = [\n",
        "    'https://www.eventbrite.com/e/international-d2c-conclave24-tickets-884043807827?aff=ebdssbdestsearch&_gl=1*sk96sp*_up*MQ..*_ga*MTcxMzg4NzUxNC4xNzE4NDczMTgy*_ga_TQVES5V6SH*MTcxODQ3MzE4MS4xLjAuMTcxODQ3MzE4MS4wLjAuMA..',\n",
        "    'https://www.eventbrite.com/e/red-bull-bc-one-cypher-india-tickets-910465897007?aff=ebdssbdestsearch&keep_tld=1',\n",
        "    'https://www.eventbrite.com/e/founders-conclave-startup-mixer-investor-and-d2c-tickets-924950771657?aff=ebdssbdestsearch&_gl=1*vynz4u*_up*MQ..*_ga*MTcxMzg4NzUxNC4xNzE4NDczMTgy*_ga_TQVES5V6SH*MTcxODQ3MzE4MS4xLjAuMTcxODQ3MzE4MS4wLjAuMA..',\n",
        "    'https://www.eventbrite.com/e/eco-consciousness-and-wellness-expo-tickets-878457408757?aff=ebdssbdestsearch&keep_tld=1',\n",
        "    'https://www.eventbrite.com/e/india-health-wellness-expo-2024-tickets-888133440027?aff=ebdssbdestsearch&_gl=1*vynz4u*_up*MQ..*_ga*MTcxMzg4NzUxNC4xNzE4NDczMTgy*_ga_TQVES5V6SH*MTcxODQ3MzE4MS4xLjAuMTcxODQ3MzE4MS4wLjAuMA..'\n",
        "]\n",
        "\n",
        "all_event_data = []\n",
        "\n",
        "for url in event_urls:\n",
        "    event_data = fetch_event_data(url)\n",
        "    all_event_data.append(event_data)\n",
        "\n",
        "# Save the scraped data to CSV file\n",
        "save_to_csv(all_event_data)\n",
        "\n",
        "print(\"Scraping completed and data saved to CSV file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGIjTb2X_-EP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}